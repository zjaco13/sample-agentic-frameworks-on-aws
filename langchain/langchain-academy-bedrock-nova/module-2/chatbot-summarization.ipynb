{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83fcadf3",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-2/chatbot-summarization.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239436-lesson-5-chatbot-w-summarizing-messages-and-memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651ead9-5504-45ee-938d-f91ac78dddd1",
   "metadata": {},
   "source": [
    "# Chatbot with message summarization\n",
    "\n",
    "## Review\n",
    "\n",
    "We've covered how to customize graph state schema and reducer. \n",
    " \n",
    "We've also shown a number of ways to trim or filter messages in graph state. \n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's take it one step further! \n",
    "\n",
    "Rather than just trimming or filtering messages, we'll show how to use LLMs to produce a running summary of the conversation.\n",
    " \n",
    "This allows us to retain a compressed representation of the full conversation, rather than just removing it with trimming or filtering.\n",
    "\n",
    "We'll incorporate this summarization into a simple Chatbot.  \n",
    "\n",
    "And we'll equip that Chatbot with memory, supporting long-running conversations without incurring high token cost / latency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "000a6daa-92ad-4e57-a060-d1c81176eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_core langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b96e7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09201a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddfce9-3a9b-4b35-a76d-28265515aabd",
   "metadata": {},
   "source": [
    "We'll use [LangSmith](https://docs.smith.langchain.com/) for [tracing](https://docs.smith.langchain.com/concepts/tracing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464856d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "537ade30-6a0e-4b6b-8bcd-ce90790b6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock   \n",
    "model = ChatBedrock(model_id=\"us.amazon.nova-pro-v1:0\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3afac3-8b7a-45db-a3c1-7e4125c1bc8b",
   "metadata": {},
   "source": [
    "We'll use `MessagesState`, as before.\n",
    "\n",
    "In addition to the built-in `messages` key, we'll now include a custom key (`summary`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "948e60f0-5c76-4235-b40e-cf523205d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "class State(MessagesState):\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855ea31-5cc1-4277-a189-0b72459f67ec",
   "metadata": {},
   "source": [
    "We'll define a node to call our LLM that incorporates a summary, if it exists, into the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3f7d19b-afe0-4381-9b1a-0a832b162e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882042c-b42d-4d52-a6a7-6ec8efa72450",
   "metadata": {},
   "source": [
    "We'll define a node to produce a summary.\n",
    "\n",
    "Note, here we'll use `RemoveMessage` to filter our state after we've produced the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78c7aa59-3760-4e76-93f1-bc713e3ec39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f982993e-f4be-4ff7-9a38-886f75398b3d",
   "metadata": {},
   "source": [
    "We'll add a conditional edge to determine whether to produce a summary based on the conversation length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b507665d-7f5d-442a-b498-218c94c5dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a838f4c-7067-4f7f-a4c4-6654e11214cd",
   "metadata": {},
   "source": [
    "## Adding memory\n",
    "\n",
    "Recall that [state is transient](https://github.com/langchain-ai/langgraph/discussions/352#discussioncomment-9291220) to a single graph execution.\n",
    "\n",
    "This limits our ability to have multi-turn conversations with interruptions. \n",
    "\n",
    "As introduced at the end of Module 1, we can use [persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/) to address this! \n",
    " \n",
    "LangGraph can use a checkpointer to automatically save the graph state after each step.\n",
    "\n",
    "This built-in persistence layer gives us memory, allowing LangGraph to pick up from the last state update. \n",
    "\n",
    "As we previously showed, one of the easiest to work with is `MemorySaver`, an in-memory key-value store for Graph state.\n",
    "\n",
    "All we need to do is compile the graph with a checkpointer, and our graph has memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d57516d-f9f1-4d3c-a84a-7277b5ce6df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0bd5d23-ac3b-4496-a049-9a9f97d2feb9",
   "metadata": {},
   "source": [
    "## Threads\n",
    "\n",
    "The checkpointer saves the state at each step as a checkpoint.\n",
    "\n",
    "These saved checkpoints can be grouped into a `thread` of conversation.\n",
    "\n",
    "Think about Slack as an analog: different channels carry different conversations.\n",
    "\n",
    "Threads are like Slack channels, capturing grouped collections of state (e.g., conversation).\n",
    "\n",
    "Below, we use `configurable` to set a thread ID.\n",
    "\n",
    "![state.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbadf3b379c2ee621adfd1_chatbot-summarization1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2566c93b-13e6-4a53-bc0f-b00fff691d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Lance! It's nice to meet you. How can I assist you today? Are you looking for information on a specific topic, need help with a problem, or perhaps you have a question about something? Let me know how I can help!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "While I don't have personal information about individuals unless it's shared during our conversation, you've already told me that your name is Lance. It's important to note that I maintain user privacy and confidentiality. I can't access personal information about you or any other individual without their consent. If you have any questions or need information on a different topic, feel free to ask!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great to hear, Lance! The San Francisco 49ers are a professional American football team based in the San Francisco Bay Area. They compete in the National Football League (NFL) as a member club of the league's National Football Conference (NFC) West division.\n",
      "\n",
      "The 49ers have a rich history, with multiple Super Bowl victories, and are known for their passionate fan base. They have had many legendary players over the years, including Joe Montana, Jerry Rice, and Steve Young, among others.\n",
      "\n",
      "If you have any questions about the 49ers, their history, players, or anything else related to the team, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"what's my name?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"i like the 49ers!\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e5b63-5e8b-486e-baa0-a45521e2fbc2",
   "metadata": {},
   "source": [
    "Now, we don't yet have a summary of the state because we still have < = 6 messages.\n",
    "\n",
    "This was set in `should_continue`. \n",
    "\n",
    "```\n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "```\n",
    "\n",
    "We can pick up the conversation because we have the thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91b82aaa-17f9-49e2-9528-f4b22e23ebcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a93e9-f716-4980-8edf-94115017d865",
   "metadata": {},
   "source": [
    "The `config` with thread ID allows us to proceed from the previously logged state!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24b34f0f-62ef-4008-8e96-480cbe92ea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As of my last training data in October 2023, Nick Bosa is indeed one of the highest-paid defensive players in the NFL. In April 2021, he signed a five-year contract extension with the San Francisco 49ers worth $170 million, with $134.85 million guaranteed. This made him one of the highest-paid defensive players in the league at that time.\n",
      "\n",
      "However, it's important to note that the landscape of NFL contracts can change rapidly with new deals being signed. Players can negotiate new contracts, extensions, or sign with new teams, which can affect their ranking in terms of salary. For the most current information, it would be best to check the latest sources or news updates on NFL player contracts.\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"i like Nick Bosa, isn't he the highest paid defensive player?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22f1b35f-e4bb-47f6-87b1-d84d8aed9aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Certainly! Here's a summary of the conversation:\\n\\n- The user introduced themselves as Lance and expressed their liking for the San Francisco 49ers, an NFL team.\\n- Lance mentioned their admiration for Nick Bosa, a defensive player for the 49ers.\\n- It was confirmed that, as of the last training data in October 2023, Nick Bosa was one of the highest-paid defensive players in the NFL, having signed a lucrative contract extension with the 49ers in 2021.\\n- The conversation also touched on the importance of checking current sources for the latest information on NFL player contracts, as they can change rapidly.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7cc0ab-905a-4037-b7cb-69db5b89591e",
   "metadata": {},
   "source": [
    "## LangSmith\n",
    "\n",
    "Let's review the trace!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lc-academy-env)",
   "language": "python",
   "name": "lc-academy-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
