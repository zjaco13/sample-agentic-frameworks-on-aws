{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1012a788",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/breakpoints.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239469-lesson-2-breakpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa16f5-abc8-4ed3-8a71-54837fe46917",
   "metadata": {},
   "source": [
    "# Breakpoints\n",
    "\n",
    "## Review\n",
    "\n",
    "For `human-in-the-loop`, we often want to see our graph outputs as its running. \n",
    "\n",
    "We laid the foundations for this with streaming. \n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's talk about the motivations for `human-in-the-loop`:\n",
    "\n",
    "(1) `Approval` - We can interrupt our agent, surface state to a user, and allow the user to accept an action\n",
    "\n",
    "(2) `Debugging` - We can rewind the graph to reproduce or avoid issues\n",
    "\n",
    "(3) `Editing` - You can modify the state \n",
    "\n",
    "LangGraph offers several ways to get or update agent state to support various `human-in-the-loop` workflows.\n",
    "\n",
    "First, we'll introduce [breakpoints](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/#simple-usage), which provide a simple way to stop the graph at specific steps. \n",
    "\n",
    "We'll show how this enables user `approval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35842345-0694-4f0a-aa62-7d4898abf653",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk langgraph-prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2cd208e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d91f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d8b4cd-e3ff-48cc-b7b2-f83fadb1c86b",
   "metadata": {},
   "source": [
    "## Breakpoints for human approval\n",
    "\n",
    "Let's re-consider the simple agent that we worked with in Module 1. \n",
    "\n",
    "Let's assume that are concerned about tool use: we want to approve the agent to use any of its tools.\n",
    " \n",
    "All we need to do is simply compile the graph with `interrupt_before=[\"tools\"]` where `tools` is our tools node.\n",
    "\n",
    "This means that the execution will be interrupted before the node `tools`, which executes the tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b94d1a90-2fe3-4b2a-a901-3bdb89e37edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a by b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "llm = ChatBedrock(model=\"us.amazon.nova-pro-v1:0\") \n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac06feae-d12b-490b-95e7-38cf40b74202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"tools\"], checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a783efac-46a9-4fb4-a1c6-a11b02540448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': \"<thinking> The user has requested to multiply two numbers, 2 and 3. I can use the 'multiply' tool to perform this operation. </thinking>\\n\"}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_XMszb8koQcqdhCc2sFBdtw'}]\n",
      "Tool Calls:\n",
      "  multiply (tooluse_XMszb8koQcqdhCc2sFBdtw)\n",
      " Call ID: tooluse_XMszb8koQcqdhCc2sFBdtw\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d49669-b1a5-42c2-bdb8-052da89bd7c4",
   "metadata": {},
   "source": [
    "We can get the state and look at the next node to call.\n",
    "\n",
    "This is a nice way to see that the graph has been interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61569596-8342-4a37-9c99-e3a9dccb18ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = graph.get_state(thread)\n",
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff47fcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='911658aa-5816-4911-bbec-80c4c74b1bdc'), AIMessage(content=[{'type': 'text', 'text': \"<thinking> The user has requested to multiply two numbers, 2 and 3. I can use the 'multiply' tool to perform this operation. </thinking>\\n\"}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_ik2eZxH_TR6UTS-Ax133Lg'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'd594adf4-b5d3-4ff5-a102-87fa84d2a2cf', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 09 Jun 2025 18:39:11 GMT', 'content-type': 'application/json', 'content-length': '420', 'connection': 'keep-alive', 'x-amzn-requestid': 'd594adf4-b5d3-4ff5-a102-87fa84d2a2cf'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [997]}, 'model_name': 'us.amazon.nova-pro-v1:0'}, id='run--a07fa0a3-382f-4058-a8ba-3bbc4bc4f62b-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'tooluse_ik2eZxH_TR6UTS-Ax133Lg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 556, 'output_tokens': 53, 'total_tokens': 609})]}, next=('tools',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f045610-8ed3-68e8-8001-63a372e2b54b'}}, metadata={'source': 'loop', 'writes': {'assistant': {'messages': [AIMessage(content=[{'type': 'text', 'text': \"<thinking> The user has requested to multiply two numbers, 2 and 3. I can use the 'multiply' tool to perform this operation. </thinking>\\n\"}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_ik2eZxH_TR6UTS-Ax133Lg'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'd594adf4-b5d3-4ff5-a102-87fa84d2a2cf', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 09 Jun 2025 18:39:11 GMT', 'content-type': 'application/json', 'content-length': '420', 'connection': 'keep-alive', 'x-amzn-requestid': 'd594adf4-b5d3-4ff5-a102-87fa84d2a2cf'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [997]}, 'model_name': 'us.amazon.nova-pro-v1:0'}, id='run--a07fa0a3-382f-4058-a8ba-3bbc4bc4f62b-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'tooluse_ik2eZxH_TR6UTS-Ax133Lg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 556, 'output_tokens': 53, 'total_tokens': 609})]}}, 'step': 1, 'parents': {}, 'thread_id': '1'}, created_at='2025-06-09T18:39:11.239389+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f045610-818c-6306-8000-d200f46ffc04'}}, tasks=(PregelTask(id='ef74556a-859f-2649-8b93-1097a1d05db8', name='tools', path=('__pregel_pull', 'tools'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a954869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='109af51b-1c13-4d4b-a2df-f495fb617108'), AIMessage(content=[{'type': 'text', 'text': \"<thinking> The user has requested to multiply two numbers, 2 and 3. I can use the 'multiply' tool to perform this operation. </thinking>\\n\"}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_XMszb8koQcqdhCc2sFBdtw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '5171f082-54e8-42d6-ad76-b28c299aacca', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 09 Jun 2025 18:47:26 GMT', 'content-type': 'application/json', 'content-length': '420', 'connection': 'keep-alive', 'x-amzn-requestid': '5171f082-54e8-42d6-ad76-b28c299aacca'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [911]}, 'model_name': 'us.amazon.nova-pro-v1:0'}, id='run--025e0dd2-40a2-4c88-8082-7f128713ac5b-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'tooluse_XMszb8koQcqdhCc2sFBdtw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 556, 'output_tokens': 53, 'total_tokens': 609})]}, next=('tools',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f045622-fd79-6268-8001-34596c17e4a1'}}, metadata={'source': 'loop', 'writes': {'assistant': {'messages': [AIMessage(content=[{'type': 'text', 'text': \"<thinking> The user has requested to multiply two numbers, 2 and 3. I can use the 'multiply' tool to perform this operation. </thinking>\\n\"}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_XMszb8koQcqdhCc2sFBdtw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '5171f082-54e8-42d6-ad76-b28c299aacca', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 09 Jun 2025 18:47:26 GMT', 'content-type': 'application/json', 'content-length': '420', 'connection': 'keep-alive', 'x-amzn-requestid': '5171f082-54e8-42d6-ad76-b28c299aacca'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [911]}, 'model_name': 'us.amazon.nova-pro-v1:0'}, id='run--025e0dd2-40a2-4c88-8082-7f128713ac5b-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'tooluse_XMszb8koQcqdhCc2sFBdtw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 556, 'output_tokens': 53, 'total_tokens': 609})]}}, 'step': 1, 'parents': {}, 'thread_id': '1'}, created_at='2025-06-09T18:47:26.025353+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f045622-f33f-6342-8000-eb91b4d5dfe0'}}, tasks=(PregelTask(id='1eb8587f-1593-1e37-46bc-9fec9d210c44', name='tools', path=('__pregel_pull', 'tools'), error=None, interrupts=(), state=None, result=None),), interrupts=())\n",
      "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='109af51b-1c13-4d4b-a2df-f495fb617108')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f045622-f33f-6342-8000-eb91b4d5dfe0'}}, metadata={'source': 'loop', 'writes': None, 'step': 0, 'parents': {}, 'thread_id': '1'}, created_at='2025-06-09T18:47:24.953045+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f045622-f338-6fba-bfff-0b0f5272f1fe'}}, tasks=(PregelTask(id='d4e327bf-e13b-30cd-422c-9b6535d21751', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result={'messages': [AIMessage(content=[{'type': 'text', 'text': \"<thinking> The user has requested to multiply two numbers, 2 and 3. I can use the 'multiply' tool to perform this operation. </thinking>\\n\"}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_XMszb8koQcqdhCc2sFBdtw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '5171f082-54e8-42d6-ad76-b28c299aacca', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 09 Jun 2025 18:47:26 GMT', 'content-type': 'application/json', 'content-length': '420', 'connection': 'keep-alive', 'x-amzn-requestid': '5171f082-54e8-42d6-ad76-b28c299aacca'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [911]}, 'model_name': 'us.amazon.nova-pro-v1:0'}, id='run--025e0dd2-40a2-4c88-8082-7f128713ac5b-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'tooluse_XMszb8koQcqdhCc2sFBdtw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 556, 'output_tokens': 53, 'total_tokens': 609})]}),), interrupts=())\n",
      "StateSnapshot(values={'messages': []}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f045622-f338-6fba-bfff-0b0f5272f1fe'}}, metadata={'source': 'input', 'writes': {'__start__': {'messages': HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={})}}, 'step': -1, 'parents': {}, 'thread_id': '1'}, created_at='2025-06-09T18:47:24.950510+00:00', parent_config=None, tasks=(PregelTask(id='06831c3b-5178-f744-7180-ca65ce5491b4', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'messages': HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={})}),), interrupts=())\n"
     ]
    }
   ],
   "source": [
    "for h in graph.get_state_history(thread):\n",
    "    print(h)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fea0fb5-3145-4f34-bcc0-9c9e8972d6b4",
   "metadata": {},
   "source": [
    "Now, we'll introduce a nice trick.\n",
    "\n",
    "When we invoke the graph with `None`, it will just continue from the last state checkpoint!\n",
    "\n",
    "![breakpoints.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbae7985b747dfed67775d_breakpoints1.png)\n",
    "\n",
    "For clarity, LangGraph will re-emit the current state, which contains the `AIMessage` with tool call.\n",
    "\n",
    "And then it will proceed to execute the following steps in the graph, which start with the tool node.\n",
    "\n",
    "We see that the tool node is run with this tool call, and it's passed back to the chat model for our final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "896a5f41-7386-4bfa-a78e-3e6ca5e26641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': \"<thinking> The user has requested to multiply two numbers, 2 and 3. I can use the 'multiply' tool to perform this operation. </thinking>\\n\"}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_XMszb8koQcqdhCc2sFBdtw'}]\n",
      "Tool Calls:\n",
      "  multiply (tooluse_XMszb8koQcqdhCc2sFBdtw)\n",
      " Call ID: tooluse_XMszb8koQcqdhCc2sFBdtw\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 2 and 3 is 6.\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f91a0c-7cc1-4437-adc7-b36abb29beb1",
   "metadata": {},
   "source": [
    "Now, lets bring these together with a specific user approval step that accepts user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a0eb50-66e3-4538-8103-207aae175154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': '<thinking> To multiply 2 and 3, I will use the multiply tool with a set to 2 and b set to 3. </thinking>\\n'}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_IJOpXgTzTPazZKXkCl8ylw'}]\n",
      "Tool Calls:\n",
      "  multiply (tooluse_IJOpXgTzTPazZKXkCl8ylw)\n",
      " Call ID: tooluse_IJOpXgTzTPazZKXkCl8ylw\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()\n",
    "\n",
    "# Get user feedback\n",
    "user_approval = input(\"Do you want to call the tool? (yes/no): \")\n",
    "\n",
    "# Check approval\n",
    "if user_approval.lower() == \"yes\":\n",
    "    \n",
    "    # If approved, continue the graph execution\n",
    "    for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "        event['messages'][-1].pretty_print()\n",
    "        \n",
    "else:\n",
    "    print(\"Operation cancelled by user.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8ff8762-6fa1-4373-954a-e7f479ee0efb",
   "metadata": {},
   "source": [
    "### Breakpoints with LangGraph API\n",
    "\n",
    "**‚ö†Ô∏è DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- üöÄ API: http://127.0.0.1:2024\n",
    "- üé® Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- üìö API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports breakpoints](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_breakpoint/#sdk-initialization). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c2eaf1-6b8b-4d80-9902-98ae5587bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb1dd890-c216-4802-9e33-b637e491e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the URL of the local development server\n",
    "from langgraph_sdk import get_client\n",
    "client = get_client(url=\"http://127.0.0.1:2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80d969-d065-45d7-8bfc-a403a0a1079b",
   "metadata": {},
   "source": [
    "As shown above, we can add `interrupt_before=[\"node\"]` when compiling the graph that is running in Studio.\n",
    "\n",
    "However, with the API, you can also pass `interrupt_before` to the stream method directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de9c5017-3a15-46f6-8edf-3997613da323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'fb7c56e1-682a-49e6-95bf-a3065a5ef374', 'example': False}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': [{'type': 'text', 'text': \"<thinking> The user wants to multiply two numbers, 2 and 3. I have a tool called 'multiply' that can perform this operation. I need to call this tool with the parameters 'a' and 'b' set to 2 and 3, respectively. </thinking>\\n\"}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_aLLB-JOoQmqy833pLNQTHQ'}], 'additional_kwargs': {}, 'response_metadata': {'ResponseMetadata': {'RequestId': 'dec96706-486a-4838-9d3b-f8a14209ccae', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 09 Jun 2025 18:47:51 GMT', 'content-type': 'application/json', 'content-length': '508', 'connection': 'keep-alive', 'x-amzn-requestid': 'dec96706-486a-4838-9d3b-f8a14209ccae'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1330]}, 'model_name': 'us.amazon.nova-pro-v1:0'}, 'type': 'ai', 'name': None, 'id': 'run--00c5caf4-93cd-44e6-8115-36eae17d480f-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'tooluse_aLLB-JOoQmqy833pLNQTHQ', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 559, 'output_tokens': 79, 'total_tokens': 638}}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=initial_input,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"tools\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64272d1-c6ee-435f-9890-9b6c3525ca6c",
   "metadata": {},
   "source": [
    "Now, we can proceed from the breakpoint just like we did before by passing the `thread_id` and `None` as the input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76284730-9c90-46c4-8295-400a49760b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': [{'type': 'text', 'text': \"<thinking> The user wants to multiply two numbers, 2 and 3. I have a tool called 'multiply' that can perform this operation. I need to call this tool with the parameters 'a' and 'b' set to 2 and 3, respectively. </thinking>\\n\"}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_aLLB-JOoQmqy833pLNQTHQ'}], 'additional_kwargs': {}, 'response_metadata': {'ResponseMetadata': {'RequestId': 'dec96706-486a-4838-9d3b-f8a14209ccae', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 09 Jun 2025 18:47:51 GMT', 'content-type': 'application/json', 'content-length': '508', 'connection': 'keep-alive', 'x-amzn-requestid': 'dec96706-486a-4838-9d3b-f8a14209ccae'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1330]}, 'model_name': 'us.amazon.nova-pro-v1:0'}, 'type': 'ai', 'name': None, 'id': 'run--00c5caf4-93cd-44e6-8115-36eae17d480f-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'tooluse_aLLB-JOoQmqy833pLNQTHQ', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 559, 'output_tokens': 79, 'total_tokens': 638}}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'bd7ee062-c821-4b1c-b771-e6229a0e9365', 'tool_call_id': 'tooluse_aLLB-JOoQmqy833pLNQTHQ', 'artifact': None, 'status': 'success'}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'ResponseMetadata': {'RequestId': '6aa54e7e-d3c9-447d-a2f0-19d2e8841f0b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 09 Jun 2025 18:48:15 GMT', 'content-type': 'application/json', 'content-length': '222', 'connection': 'keep-alive', 'x-amzn-requestid': '6aa54e7e-d3c9-447d-a2f0-19d2e8841f0b'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [488]}, 'model_name': 'us.amazon.nova-pro-v1:0'}, 'type': 'ai', 'name': None, 'id': 'run--5d4ecef4-b9ae-46c3-8c9e-f7a1347eaa59-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 664, 'output_tokens': 13, 'total_tokens': 677}}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    \"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"tools\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575970f-42e2-4d03-b18a-aacaa8233b53",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lc-academy-env)",
   "language": "python",
   "name": "lc-academy-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
